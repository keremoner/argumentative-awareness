{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c70903c7",
   "metadata": {},
   "source": [
    "# Background\n",
    "## Setup\n",
    "State space: integers from 0 to 20 sampled uniformly\n",
    "\n",
    "Utterance space: all possible closed integer intervals within the state space that have a minimum range of 3 and maximum range of 5:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{S} &= \\{0, 1, \\dots, 20\\} \\\\\n",
    "\\mathcal{U} &= \\{[0, 2], [0, 3], [0, 4], \\dots, [16, 20], [17, 20], [18, 20] \\}\n",
    "\\end{align*}\n",
    "\n",
    "## Literal Listener: L_0\n",
    "$$L_0(s \\mid u) \\propto [[u]](s) P(s) $$\n",
    "\n",
    "\\begin{align*}\n",
    "    [[u]](s) &=\n",
    "    \\left\\{\n",
    "    \\begin{aligned}\n",
    "        1 &\\quad \\text{if } a \\leq s \\leq b \\\\\n",
    "        0 &\\quad \\text{else}\n",
    "    \\end{aligned} \\quad \\text{where } u=[a,b]\n",
    "    \\right. \\\\\n",
    "\\end{align*}\n",
    "\n",
    "## Pragmatic Speaker 1: S_1\n",
    "\n",
    "We have $\\alpha$ the rationality parameter, $\\psi$ the speaker type (inf, pers+, pers-), and $\\beta$ that switches between inf and pers (+ or -) (they do not use intermediate $\\beta$ values in the RSA opinion dynamics paper)\n",
    "\n",
    "Persuasive strength does not depend on the state, and it gives more weight to utterances that have high or low expected value (relative to the literal listener) depending on pers+ or pers-. \n",
    "\n",
    "I assign 0 probability for utterances with 0 informativity, so truth condition is satisfied for both values of $\\beta$.\n",
    "\n",
    "\\begin{align*}\n",
    "    S_1(u | s, \\psi) &\\propto \\text{Inf}_{S_1}(u ; s)^{\\alpha\\beta} \\cdot \\text{PersStr}_{S_1}(u; \\psi) ^{\\alpha(1 - \\beta)} \\\\\n",
    "    \\text{Inf}_{S_1}(u ; s) &= L_0(s | u) \\\\\n",
    "    \\text{PersStr}_{S_1}(u ; \\psi) &=\n",
    "    \\left\\{\n",
    "    \\begin{aligned}\n",
    "        \\frac{E_{L_0}[s | u] - \\text{min}(S)}{\\text{max}(S) - \\text{min}(S)} &\\quad \\text{if } \\psi = \\text{pers}^+ \\\\\n",
    "        \\frac{\\text{max}(S) - E_{L_0}[s | u]}{\\text{max}(S) - \\text{min}(S)} &\\quad \\text{if } \\psi = \\text{pers}^-\\\\\n",
    "        1 &\\quad \\text{if } \\psi = \\text{inf}\n",
    "    \\end{aligned}\n",
    "    \\right. \\\\\n",
    "    \\beta &=\n",
    "    \\left\\{\n",
    "    \\begin{aligned}\n",
    "        1 &\\quad \\text{if } \\psi = \\text{inf} \\\\\n",
    "        0 &\\quad \\text{otherwise}\n",
    "    \\end{aligned}\n",
    "    \\right. \\\\\n",
    "\\end{align*}\n",
    "\n",
    "## Pragmatic Listener 1 (informative): L_1^{inf}\n",
    "\n",
    "This is the standard pragmatic listener. Assumes the speaker is informative:\n",
    "\n",
    "$$L_1^{\\text{inf}}(s \\mid u) \\propto L_1(s) \\cdot S_1(u \\mid s, \\text{\"inf\"})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9351083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "def create_all_utterances(min_interval, max_interval, domain):\n",
    "    min_val, max_val = domain\n",
    "    domain_range = max_val - min_val + 1\n",
    "    if min_interval < 1 or max_interval > domain_range or min_interval >= max_interval:\n",
    "        raise ValueError(\"Interval out of bounds of the domain.\")\n",
    "    utterances = []\n",
    "    for interval_range in range(min_interval, max_interval + 1):\n",
    "        for start in range(min_val, max_val + 1):\n",
    "            end = start + interval_range - 1\n",
    "            if end <= max_val:\n",
    "                utterances.append((start, end))\n",
    "                \n",
    "    return utterances\n",
    "\n",
    "def literal_listener(utterance, domain):\n",
    "    min_val, max_val = domain\n",
    "    start, end = utterance\n",
    "    if start < min_val or end > max_val or start > end:\n",
    "        raise ValueError(\"Utterance out of bounds of the domain.\")\n",
    "    x = list(range(min_val, max_val + 1))\n",
    "    pmf = np.zeros(len(x))\n",
    "    pmf[start: end + 1] = 1 / (end - start + 1)\n",
    "    return x, pmf\n",
    "\n",
    "# def literal_listener(utterance, domain):\n",
    "#     if utterance == 0:\n",
    "#         return [0, 1, 2, 3], np.array([0.5, 0, 0.25, 0.25])\n",
    "#     else:\n",
    "#         return [0, 1, 2, 3], np.array([0.5, 0.5, 0, 0])\n",
    "\n",
    "def literal_speaker(state, utterances, domain):\n",
    "    result = {u: 0.0 for u in utterances}\n",
    "    for utt in utterances:\n",
    "        x, pmf = literal_listener(utt, domain)\n",
    "        x = np.array(x)\n",
    "        if pmf[np.where(x == state)[0][0]] > 0:\n",
    "            result[utt] += 1\n",
    "    result = {k: v / sum(result.values()) for k, v in result.items()}\n",
    "    return result\n",
    "\n",
    "def informativeness_all_utterances(state, utterances, domain):\n",
    "\n",
    "    result = {}\n",
    "    for utt in utterances:\n",
    "        x, pmf = literal_listener(utt, domain)\n",
    "        x = np.array(x)\n",
    "        pmf = np.array(pmf)\n",
    "        result[utt] = pmf[np.where(x == state)[0][0]]\n",
    "    return result\n",
    "\n",
    "def persuasiveness_all_utterances(pers, utterances, domain):\n",
    "        \n",
    "    result = {u: 0.0 for u in utterances}\n",
    "\n",
    "    for utt in utterances:\n",
    "        if pers == \"inf\":\n",
    "            result[utt] = 1\n",
    "        else:\n",
    "            x, pmf = literal_listener(utt, domain)\n",
    "            for i in range(len(pmf)):\n",
    "                result[utt] += x[i] * pmf[i]\n",
    "            result[utt] = (result[utt] - domain[0])/ (domain[1] - domain[0])\n",
    "            if pers == \"low\":\n",
    "                result[utt] = 1 - result[utt]\n",
    "    return result\n",
    "\n",
    "def pragmatic_speaker(state, pers, utterances, domain, alpha=1.0):\n",
    "    # Compute informativeness and persuasiveness\n",
    "    informativeness = informativeness_all_utterances(state, utterances, domain)\n",
    "    persuasiveness = persuasiveness_all_utterances(pers, utterances, domain)\n",
    "\n",
    "    if pers == \"inf\":\n",
    "        beta = 1.0\n",
    "    else:\n",
    "        beta = 0.0\n",
    "        \n",
    "    scores = []\n",
    "    for utt in utterances:\n",
    "        info = informativeness.get(utt, 0.0)\n",
    "        pers_val = persuasiveness.get(utt, 0.0)\n",
    "\n",
    "        if info > 0:\n",
    "            score = (info ** (alpha * beta)) * (pers_val ** (alpha * (1 - beta)))\n",
    "        else:\n",
    "            score = 0.0\n",
    "        scores.append(score)\n",
    "\n",
    "    scores = np.array(scores)\n",
    "    probs = scores / np.sum(scores) if np.sum(scores) > 0 else np.ones_like(scores) / len(scores)\n",
    "    return {utt: p for utt, p in zip(utterances, probs)}\n",
    "\n",
    "def pragmatic_listener(utt, utterances, domain, psi_prior, alpha):\n",
    "    state_prior = 1.0 / (domain[1] - domain[0] + 1)\n",
    "    x = []\n",
    "    pmf = []\n",
    "    # inf case\n",
    "    all_states = np.arange(domain[0], domain[1] + 1)\n",
    "    for state in all_states:\n",
    "        res = 0\n",
    "        for psi, psi_prob in psi_prior.items():\n",
    "            res += pragmatic_speaker(state, psi, utterances, domain, alpha)[utt] * psi_prob \n",
    "        x.append(state)\n",
    "        pmf.append(res * state_prior)\n",
    "    pmf = np.array(pmf)\n",
    "    pmf /= np.sum(pmf)\n",
    "    return x, pmf\n",
    "\n",
    "def pragmatic_listener_inf(utt, utterances, domain, alpha=3.0):\n",
    "    state_prior = 1.0 / (domain[1] - domain[0] + 1)\n",
    "    x = []\n",
    "    pmf = []\n",
    "    # inf case\n",
    "    all_states = np.arange(domain[0], domain[1] + 1)\n",
    "    for state in all_states:\n",
    "        res_inf = pragmatic_speaker(state, \"inf\", utterances, domain, alpha=alpha)[utt]\n",
    "        x.append(state)\n",
    "        pmf.append(res_inf * state_prior)\n",
    "    pmf = np.array(pmf)\n",
    "    pmf /= np.sum(pmf)\n",
    "    return x, pmf\n",
    "\n",
    "def pragmatic_listener_op(utt, utterances, domain, psi_prior, alpha):\n",
    "    state_prior = 1.0 / (domain[1] - domain[0] + 1)\n",
    "    result = {\"inf\": 0.0, \"high\": 0.0, \"low\": 0.0}\n",
    "    # op case\n",
    "    all_states = np.arange(domain[0], domain[1] + 1)\n",
    "    for psi, prob in psi_prior.items():\n",
    "        for state in all_states:\n",
    "            result[psi] += pragmatic_speaker(state, psi, utterances, domain, alpha=alpha)[utt] * state_prior * prob\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520163fa",
   "metadata": {},
   "source": [
    "# Calculating Suspicion\n",
    "\n",
    "To calculate the suspicion, we first get the posterior probabilities for all utterances after the pragmatic listener hears an utterance $u^*$:\n",
    "$$P(u' | u^*) = \\sum_{s \\in \\mathcal{S}} S_1(u'|s, \\text{\"inf\"}) \\cdot L_1^{\\text{inf}}(s | u^*)$$\n",
    "\n",
    "We define an entropy/inverse-precision of an utterance as the entropy of the literal listener's state distribution after hearing that utterance, let's denote it as $\\text{Ent(u)}$:\n",
    "\n",
    "$$\\text{Ent(u)} = \\sum_{s \\in \\mathcal{S}} \\log_2(L_0(s | u)) \\cdot L_0(s | u)$$\n",
    "\n",
    "Using this posterior utterance probabilities, we get a distribution of entropy $E$, let's denote its PMF with $p_E(x)$.\n",
    "\n",
    "$$p_E(x) = \\sum_{u' \\in \\mathcal{U} \\land \\text{Ent}(u') = x} P(u' | u^*) $$\n",
    "\n",
    "We want to calculate how surprising $\\text{Ent}(u^*)$ considering the distribution $p_E(x)$, and use this surprisal as a quantity for suspicion towards persuasion. I may have misunderstood what we discussed as two different methods, but from what I understood, the first method is 1) the tail probability / p-value which is the method I understood firstly and found more intuitive.\n",
    "\n",
    "1) tail probability / p-value is the probability that the speaker could have used an utterance with a lower entropy (higher precision) than $u^*$.\n",
    "$$sus(u^*) \\propto \\sum_{x < \\text{Ent}(u ^ *)} p_E(x)$$\n",
    "\n",
    "I am not sure if I understood the second method correctly but to get a surprisal value we can use the 2) self-information / probability of $\\text{Ent}(u ^ *)$ given $p_E(x)$. \n",
    "\n",
    "2) self-information / probability is the surprisal amount that $\\text{Ent}(u ^ *)$ carries:\n",
    "$$sus(u^*) \\propto -\\log_2(p_E(\\text{Ent}(u ^ *))) \\quad \\text{ or } \\quad sus(u^*) \\propto \\frac{1}{p_E(\\text{Ent} (u ^ *))} \\quad \\text{ or } \\quad sus(u^*) \\propto 1 - p_E(\\text{Ent}(u ^ *))$$\n",
    "\n",
    "Is this what we want? or something else?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7326a99a",
   "metadata": {},
   "source": [
    "# P-value: at least as extreme as\n",
    "\n",
    "Your suggestion:\n",
    "\n",
    "Change\n",
    "\n",
    "\\begin{align}\n",
    "sus(u^*) &\\propto \\sum_{x < \\text{Ent}(u ^ *)} p_E(x) \\tag{5} \\\\\n",
    "&\\text{ to} \\nonumber \\\\\n",
    "sus(u^*) &\\propto \\sum_{x \\le \\text{Ent}(u ^ *)} p_E(x) \\tag{6}\n",
    "\\end{align}\n",
    "\n",
    "I think it should be $<$ because $sus$ here should be interpreted as not the p-value, but 1 minus p-value. If we look at this as hypothesis testing, then I think our null hypothesis would be that the speaker is informative. If we use the entropy as a test statistics, then a more extreme value under the null hypothesis is high-entropy, so p-value corresponds to the sum of the right tail of $p_E$ with $\\ge$. We reject the null hypothesis as p-value gets lower which is analogue to having higher suspicion against informativity where suspicion corresponds to 1 minus p-value which is the sum of the left tail of $p_E$ with $<$.\n",
    "\n",
    "\\begin{align}\n",
    "\\text{p-value} = \\sum_{x \\ge \\text{Ent}(u ^ *)} p_E(x) \\nonumber\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f0e08e",
   "metadata": {},
   "source": [
    "# Prior vs Posterior\n",
    "\n",
    "Your suggestion:\n",
    "\n",
    "Change\n",
    "\\begin{align}\n",
    "P(u' \\mid u^*) &= \\sum_{s \\in \\mathcal{S}} S_1(u' \\mid s, \\text{\"inf\"}) \\cdot L_1^{\\text{inf}}(s \\mid u^*)\\\\\n",
    "&\\text{to} \\nonumber \\\\\n",
    "P(u' \\mid u^*) &= \\sum_{s \\in \\mathcal{S}} S_1(u' \\mid s, \\text{\"inf\"}) \\cdot L_1^{\\text{inf}}(s)\n",
    "\\end{align}\n",
    "\n",
    "Given the prior for states, we can compute the prior utterance and prior entropy distributions as you mentioned in (2). However, I think there should not be conceptually a \"prior suspicion value for an utterance\" because computing suspicion for a specific utterance must include a reasoning like \"If I hear utterance $u^*$, I should suspect this amount\". I don't see why we would consider states that are known to be impossible under the precondition of computing suspicion that an utterance $u ^ *$ is heard. Do you have in mind what would the suspicion conceptually correspond to when we use (2)?\n",
    "\n",
    "I think the problem (what I consider as a problem) (2) causes is evident when we have many low-precision utterances for most of the state space and high-precision utterances for a small part of the space. Consider the following utterance space for the same state space of $[0, 20]$ where we have high-precision utterances for the part of the state space $[0, 2]$ and low-precision utterances for the part $[3, 20]$:\n",
    "\n",
    "$$\\mathcal{U}_{alt} = \\{[0, 0], [1, 1], [2, 2], [0, 2], [3, 12], [4, 13], \\dots, [11, 20]\\}$$\n",
    "\n",
    "If we use (2), then we would have most of the mass in $p_E$ in $p_E(\\text{Ent}([3, 12]))$ regardless of the utterance heard $u ^ *$. Suppose $u ^ * = [0, 2]$, then, some other part of the state space $[3, 20]$, which we should for sure know that is irrelevant after hearing $u ^ *$, will cause $sus(u ^ *)$ to be lower compared to a case where this irrelevant part of the state space have high precision utterances. Maybe, instead of using (2) directly in the p-value calculation, we can use some property of $P(u' | u^*)$ or $p_E$ calculated under (2) to get a baseline or a discount value for the suspicion amount which then would be used along with the p-value obtained using (1) when calculating suspicion for a heard utterance $u ^ *$.  \n",
    "\n",
    "What I also found as a sensible alternative to compare with (1) is the below formulation that incorporates the truthfulness assumption:\n",
    "\\begin{align}\n",
    "P(u' \\mid u^*) = \\sum_{s \\in \\mathcal{S}} S_1(u' \\mid s, \\text{\"inf\"}) \\cdot L_0(s \\mid u^*) \\tag{3}\n",
    "\\end{align}\n",
    "This should correspond to a reasoning like this:\n",
    "\n",
    "- I don't know whether the speaker is inf or pers\n",
    "\n",
    "- I know that the state the speaker observed is $s \\in [[u ^*]]$ \n",
    "\n",
    "- Using prior state beliefs, I know the probability of each state happening\n",
    "\n",
    "- $P(u' \\mid u^*)$ is the probability that an informative speaker could have said $u'$ where I know $u ^ *$ is true, and nothing more.\n",
    "\n",
    "Also, I think a more general posterior perspective instead of (1) is to use $L_1(s \\mid u^*)$ instead of $L_1^{\\text{inf}}(s \\mid u^*)$:\n",
    "\n",
    "\\begin{align}\n",
    "P(u' \\mid u^*) &= \\sum_{s \\in \\mathcal{S}} S_1(u' \\mid s, \\text{\"inf\"}) \\cdot L_1(s \\mid u^*) \\tag{4} \\\\\n",
    "&\\text{where} \\nonumber \\\\\n",
    "L_1(s \\mid u ^ *) &\\propto L_1(s) \\cdot \\sum_{\\psi'} S_1(u ^ * \\mid s, \\psi') \\cdot L_1(\\psi') \\nonumber \\\\\n",
    "&\\text{compared to} \\nonumber \\\\\n",
    "L_1^{\\text{inf}}(s \\mid u ^ *) &\\propto L_1(s) \\cdot S_1(u ^*  \\mid s, \\text{\"inf\"}) \\nonumber\n",
    "\\end{align}\n",
    "\n",
    "Then we get (1) as a special case of (4) where we have $L_1(\\psi = \\text{inf}) = 1$, and in the general case $L_1$ incorporates their prior beliefs about the speaker type when computing the state probabilities and consequently when computing the suspicion. My intuition for comparing (3) and (4) is that in (3) the listener $L_1$ is uninformed about the speaker type whereas in (4) they are, and in the special case of (1) they are assuming full informativity. I am not sure how (3) and (4) can be interpreted in terms of unawareness of persuasion. For (4), can we say the assumption/prior of full informativity is exactly the total unawareness of persuasive context even though $L_1$ considers the possible value of $\\psi = \\text{pers}$ for the variable $\\psi$? It also seems reasonable to me to say for (3) the listener is unaware of the persuasive context (actually more generally, unaware of speaker types or the variable $\\psi$ or the possible values for the variable $\\psi$), and this variable $\\psi$ (or a new value $\\text{pers}$ for the variable $\\psi$) is added to the model, which they become aware of after doing a non-bayesian revision. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2e6e0",
   "metadata": {},
   "source": [
    "# Calculating Suspicion\n",
    "\n",
    "I will use three different methods to calculate $P(u' \\mid u ^ *)$ written below:\n",
    "\n",
    "\\begin{align}\n",
    "P_1(u' \\mid u ^ *) &= \\sum_{s \\in \\mathcal{S}} S_1(u' \\mid s, \\text{\"inf\"}) \\cdot L_0(s) \\\\\n",
    "P_2(u' \\mid u ^ *) &= \\sum_{s \\in \\mathcal{S}} S_1(u' \\mid s, \\text{\"inf\"}) \\cdot L_0(s \\mid u^*) \\\\\n",
    "P_3(u' \\mid u ^ *) &= \\sum_{s \\in \\mathcal{S}} S_1(u' \\mid s, \\text{\"inf\"}) \\cdot L_1(s \\mid u^*) \\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "I will use two different test statistics to compute suspicion for each method of calculating $P(u' \\mid u ^ *)$. First one is the entropy where suspicion would correspond to hearing an utterance more precise / lower entropy than the heard utterance $u^*$, given $P(u' \\mid u^*)$:\n",
    "\\begin{align*}\n",
    "\\text{Ent(u)} &= -\\sum_{s \\in \\mathcal{S}} \\log_2(L_0(s | u)) \\cdot L_0(s | u) \\\\\n",
    "p_E(x) &= \\sum_{u' \\in \\mathcal{U} \\land \\text{Ent}(u') = x} P(u' | u^*) \\\\\n",
    "sus(u^*) &= \\sum_{x < \\text{Ent}(u ^ *)} p_E(x)\n",
    "\\end{align*}\n",
    "\n",
    "Second method is to use directly the distribution $P(u' \\mid u^*)$ and the occurence probability of $u^*$ under this distribution to compute the suspicion where it corresponds to hearing an utterance that is more probable than $u^*$ under $P(u' \\mid u^*)$:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{U}_{>u^*} &= \\{u' \\mid P(u' \\mid u^*) > P(u^*|u^*)\\} \\\\\n",
    "sus(u^*) &= \\sum_{u' \\in \\mathcal{U}_{\\le u^*}} P(u' \\mid u^*) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Better way:\n",
    "\\begin{align}\n",
    "I^{>}_{n}(u, s) &= \\{u' \\in \\mathcal{U} \\mid S_n(u' | s, \\text{\"inf\"}) > S_n(u \\mid s, \\text{\"inf\"})\\} \\nonumber \\\\\n",
    "sus_{n+1}(u^*) &= \\sum_{s \\in \\mathcal{S}} L_n(s \\mid u ^*) \\sum_{u' \\in I^{>}_{n}(u^*, s)} S_n(u' \\mid s, \\text{\"inf\"}) \\tag{4}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61bb4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utterance_prob_0(utt, utterances, domain):\n",
    "    all_states = np.arange(domain[0], domain[1] + 1)\n",
    "    prior = 1 / len(all_states)\n",
    "    utterance_probs = {u: 0.0 for u in utterances}\n",
    "    for state in all_states:\n",
    "        speaker_probs = literal_speaker(state, utterances, domain)\n",
    "        for u in utterances:\n",
    "            utterance_probs[u] += prior * speaker_probs[u]\n",
    "    return utterance_probs\n",
    "\n",
    "def get_utterance_prob_1(utt, utterances, domain, alpha=3.0):\n",
    "    all_states = np.arange(domain[0], domain[1] + 1)\n",
    "    prior = 1 / len(all_states)\n",
    "    utterance_probs = {u: 0.0 for u in utterances}\n",
    "    for state in all_states:\n",
    "        speaker_probs = pragmatic_speaker(state, \"inf\", utterances, domain, alpha=alpha)\n",
    "        for u in utterances:\n",
    "            utterance_probs[u] += prior * speaker_probs[u]\n",
    "    return utterance_probs\n",
    "\n",
    "def get_utterance_prob_2(utt, utterances, domain, alpha=3.0):\n",
    "    all_states = np.arange(domain[0], domain[1] + 1)\n",
    "    utterance_probs = {u: 0.0 for u in utterances}\n",
    "    for state in all_states:\n",
    "        x_state, pmf_state = literal_listener(utt, domain)\n",
    "        speaker_probs = pragmatic_speaker(state, \"inf\", utterances, domain, alpha=alpha)\n",
    "        for u in utterances:\n",
    "            utterance_probs[u] += pmf_state[x_state.index(state)] * speaker_probs[u]\n",
    "    return utterance_probs\n",
    "\n",
    "def get_utterance_prob_3(utt, utterances, domain, psi_prior, alpha=3.0):\n",
    "    all_states = np.arange(domain[0], domain[1] + 1)\n",
    "    utterance_probs = {u: 0.0 for u in utterances}\n",
    "    for state in all_states:\n",
    "        x_state, pmf_state = pragmatic_listener(utt, utterances, domain, psi_prior=psi_prior, alpha=alpha)\n",
    "        speaker_probs = pragmatic_speaker(state, \"inf\", utterances, domain, alpha=alpha)\n",
    "        for u in utterances:\n",
    "            utterance_probs[u] += pmf_state[x_state.index(state)] * speaker_probs[u]\n",
    "    return utterance_probs\n",
    "\n",
    "def get_entropy(utt, domain):\n",
    "    x, pmf = literal_listener(utt, domain)\n",
    "    pmf = pmf[pmf > 0]  # Filter out zero probabilities\n",
    "    entropy = -np.sum(pmf * np.log2(pmf))\n",
    "    return entropy\n",
    "\n",
    "def get_entropy_dist(domain, utterance_prob):\n",
    "    entropies = {}\n",
    "    for u, prob in utterance_prob.items():\n",
    "        entropy = get_entropy(u, domain)\n",
    "        entropies[entropy] = entropies.get(entropy, 0) + prob\n",
    "    x, pmf = zip(*sorted(entropies.items()))\n",
    "    return x, pmf\n",
    "\n",
    "def sus_entropy_l(utt, domain, entropy_dist):\n",
    "    x_ent, pmf_ent = entropy_dist\n",
    "    utt_ent = get_entropy(utt, domain)\n",
    "    suspicion = 0\n",
    "    for i in range(len(x_ent)):\n",
    "        if np.isclose(x_ent[i], utt_ent, rtol=1e-9, atol=1e-12):\n",
    "            continue\n",
    "        elif x_ent[i] < utt_ent:\n",
    "            suspicion += pmf_ent[i]\n",
    "    return suspicion\n",
    "\n",
    "def sus_probability(utt, utterance_prob):\n",
    "    utt_prob = utterance_prob.get(utt, 0.0)\n",
    "    suspicion = 0\n",
    "    for u, prob in utterance_prob.items():\n",
    "        if np.isclose(prob, utt_prob, rtol=1e-9, atol=1e-12):\n",
    "            continue\n",
    "        elif prob > utt_prob:\n",
    "            suspicion += prob\n",
    "    return suspicion\n",
    "\n",
    "def sus_proper(utt, utterances, domain, alpha=1.0):\n",
    "    all_states = np.arange(domain[0], domain[1] + 1)\n",
    "    sus = 0.0\n",
    "    listener_x, listener_pmf = literal_listener(utt, domain)\n",
    "    for state in all_states:\n",
    "        speaker_result = pragmatic_speaker(state, \"inf\", utterances, domain, alpha=alpha)\n",
    "        for u, prob in speaker_result.items():\n",
    "            if np.isclose(prob, speaker_result[utt], rtol=1e-9, atol=1e-12):\n",
    "                continue\n",
    "            elif prob > speaker_result[utt]:\n",
    "                sus += prob * listener_pmf[listener_x.index(state)]\n",
    "    return sus\n",
    "\n",
    "def sus_proper(utt, utterances, domain, alpha=1.0):\n",
    "    all_states = np.arange(domain[0], domain[1] + 1)\n",
    "    result_psi = {\"inf\": 1.0, \"high\": 0.0, \"low\": 0.0}\n",
    "    sus = 0.0\n",
    "    high_result = persuasiveness_all_utterances(\"high\", utterances, domain)\n",
    "    low_result = persuasiveness_all_utterances(\"low\", utterances, domain)\n",
    "    listener_x, listener_pmf = literal_listener(utt, domain)\n",
    "    for state in all_states:\n",
    "        speaker_result = pragmatic_speaker(state, \"inf\", utterances, domain, alpha=alpha)\n",
    "        for u, prob in speaker_result.items():\n",
    "            if np.isclose(prob, speaker_result[utt], rtol=1e-9, atol=1e-12):\n",
    "                continue\n",
    "            elif prob > speaker_result[utt]:\n",
    "                sus += prob * listener_pmf[listener_x.index(state)]\n",
    "                result_psi[\"inf\"] -= sus\n",
    "                if np.isclose(high_result[u], low_result[u], rtol=1e-9, atol=1e-12):\n",
    "                    result_psi[\"high\"] += sus / 2.0\n",
    "                    result_psi[\"low\"] += sus / 2.0\n",
    "                else:\n",
    "                    if high_result[u] > low_result[u]:\n",
    "                        result_psi[\"high\"] += sus\n",
    "                    else:\n",
    "                        result_psi[\"low\"] += sus\n",
    "    return sus, result_psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114ecb9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(1, 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m utterance = (\u001b[32m1\u001b[39m, \u001b[32m7\u001b[39m)\n\u001b[32m      6\u001b[39m alpha = \u001b[32m3.0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m x_1, pmf_1 = pragmatic_listener_inf(utt, utterances, domain, alpha=alpha)\n\u001b[32m      9\u001b[39m sus_psi_prior = sus_proper(utt, utterances, domain, alpha=alpha)\n\u001b[32m     10\u001b[39m psi_prior = sus_psi_prior\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 120\u001b[39m, in \u001b[36mpragmatic_listener_inf\u001b[39m\u001b[34m(utt, utterances, domain, alpha)\u001b[39m\n\u001b[32m    118\u001b[39m all_states = np.arange(domain[\u001b[32m0\u001b[39m], domain[\u001b[32m1\u001b[39m] + \u001b[32m1\u001b[39m)\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m all_states:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     res_inf = pragmatic_speaker(state, \u001b[33m\"\u001b[39m\u001b[33minf\u001b[39m\u001b[33m\"\u001b[39m, utterances, domain, alpha=alpha)[utt]\n\u001b[32m    121\u001b[39m     x.append(state)\n\u001b[32m    122\u001b[39m     pmf.append(res_inf * state_prior)\n",
      "\u001b[31mKeyError\u001b[39m: (1, 7)"
     ]
    }
   ],
   "source": [
    "utterances = [0, 1]\n",
    "literal_listener(0, (0, 3))\n",
    "pragmatic_speaker(3, \"inf\", utterances, (0, 3), alpha=1.0)\n",
    "pragmatic_listener(1, utterances, (0, 3), psi_prior={\"inf\": 1.0, \"high\": 0.0, \"low\": 0.0}, alpha=4.0)\n",
    "\n",
    "print(sus_proper(0, utterances, (0, 3), alpha=1.0))\n",
    "res_1 = get_utterance_prob_2(0, utterances, (0, 3), alpha=1.0)\n",
    "print(sus_entropy_l(0, (0, 3), get_entropy_dist((0, 3), res_1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dbf2bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utterance: (0, 2), Probability: 0.06638577412305985\n",
      "Utterance: (1, 3), Probability: 0.04135285315125242\n",
      "Utterance: (2, 4), Probability: 0.03422478398105448\n",
      "Utterance: (3, 5), Probability: 0.03313178518568016\n",
      "Utterance: (4, 6), Probability: 0.03293142586281879\n",
      "Utterance: (5, 7), Probability: 0.03293142586281879\n",
      "Utterance: (6, 8), Probability: 0.03293142586281879\n",
      "Utterance: (7, 9), Probability: 0.03293142586281879\n",
      "Utterance: (8, 10), Probability: 0.03293142586281879\n",
      "Utterance: (9, 11), Probability: 0.03293142586281879\n",
      "Utterance: (10, 12), Probability: 0.03293142586281879\n",
      "Utterance: (11, 13), Probability: 0.03293142586281879\n",
      "Utterance: (12, 14), Probability: 0.03293142586281879\n",
      "Utterance: (13, 15), Probability: 0.03293142586281878\n",
      "Utterance: (14, 16), Probability: 0.03293142586281878\n",
      "Utterance: (15, 17), Probability: 0.03313178518568016\n",
      "Utterance: (16, 18), Probability: 0.03422478398105448\n",
      "Utterance: (17, 19), Probability: 0.04135285315125242\n",
      "Utterance: (18, 20), Probability: 0.06638577412305985\n",
      "Utterance: (0, 3), Probability: 0.01840612883031952\n",
      "Utterance: (1, 4), Probability: 0.012418153135393227\n",
      "Utterance: (2, 5), Probability: 0.010726628908481022\n",
      "Utterance: (3, 6), Probability: 0.010467255170906842\n",
      "Utterance: (4, 7), Probability: 0.01041970896440751\n",
      "Utterance: (5, 8), Probability: 0.01041970896440751\n",
      "Utterance: (6, 9), Probability: 0.01041970896440751\n",
      "Utterance: (7, 10), Probability: 0.01041970896440751\n",
      "Utterance: (8, 11), Probability: 0.01041970896440751\n",
      "Utterance: (9, 12), Probability: 0.01041970896440751\n",
      "Utterance: (10, 13), Probability: 0.01041970896440751\n",
      "Utterance: (11, 14), Probability: 0.010419708964407508\n",
      "Utterance: (12, 15), Probability: 0.010419708964407508\n",
      "Utterance: (13, 16), Probability: 0.010419708964407508\n",
      "Utterance: (14, 17), Probability: 0.010467255170906839\n",
      "Utterance: (15, 18), Probability: 0.010726628908481018\n",
      "Utterance: (16, 19), Probability: 0.012418153135393226\n",
      "Utterance: (17, 20), Probability: 0.018406128830319515\n",
      "Utterance: (0, 4), Probability: 0.006884902853483366\n",
      "Utterance: (1, 5), Probability: 0.004922762977769918\n",
      "Utterance: (2, 6), Probability: 0.004368484319095325\n",
      "Utterance: (3, 7), Probability: 0.004283492732767019\n",
      "Utterance: (4, 8), Probability: 0.004267912791821317\n",
      "Utterance: (5, 9), Probability: 0.004267912791821317\n",
      "Utterance: (6, 10), Probability: 0.004267912791821317\n",
      "Utterance: (7, 11), Probability: 0.004267912791821317\n",
      "Utterance: (8, 12), Probability: 0.004267912791821317\n",
      "Utterance: (9, 13), Probability: 0.004267912791821317\n",
      "Utterance: (10, 14), Probability: 0.004267912791821317\n",
      "Utterance: (11, 15), Probability: 0.004267912791821317\n",
      "Utterance: (12, 16), Probability: 0.004267912791821316\n",
      "Utterance: (13, 17), Probability: 0.004283492732767017\n",
      "Utterance: (14, 18), Probability: 0.0043684843190953246\n",
      "Utterance: (15, 19), Probability: 0.004922762977769916\n",
      "Utterance: (16, 20), Probability: 0.006884902853483364\n",
      "Utterance: (1, 3), Suspicion Entropy Value: 0\n",
      "Utterance: (1, 3), Suspicion Probability: 0.1327715482461197\n"
     ]
    }
   ],
   "source": [
    "min_interval = 3\n",
    "max_interval = 5\n",
    "domain = (0, 20)\n",
    "utterances = create_all_utterances(min_interval, max_interval, domain)\n",
    "utterance = (1, 3)\n",
    "psi_prior = {\"inf\": 1.0, \"high\": 0.0, \"low\": 0.0}\n",
    "\n",
    "res_1 = get_utterance_prob_1(utterance, utterances, domain, alpha=5.0)\n",
    "res_2 = get_utterance_prob_2(utterance, utterances, domain, alpha=5.0)\n",
    "res_3 = get_utterance_prob_3(utterance, utterances, domain, psi_prior, alpha=5.0)\n",
    "\n",
    "for utt, prob in res_1.items():\n",
    "    print(f\"Utterance: {utt}, Probability: {prob}\")\n",
    "\n",
    "entropy_dist = get_entropy_dist(domain, res_1)\n",
    "sus_entropy_l_value = sus_entropy_l(utterance, domain, entropy_dist)\n",
    "sus_prob = sus_probability(utterance, res_1)\n",
    "print(f\"Utterance: {utterance}, Suspicion Entropy Value: {sus_entropy_l_value}\")\n",
    "print(f\"Utterance: {utterance}, Suspicion Probability: {sus_prob}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7970fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_table(df, sort_by=None, top_n=10, decimals=3):\n",
    "    \"\"\"\n",
    "    Display a nice-looking table of suspicion results.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Results DataFrame\n",
    "        sort_by (str, optional): Column to sort by\n",
    "        top_n (int): Number of rows to show\n",
    "        decimals (int): Rounding of floats\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame (console) or pd.Styler (Jupyter)\n",
    "    \"\"\"\n",
    "    # Round floats\n",
    "    #df = df.round(decimals)\n",
    "\n",
    "    # Optional sort\n",
    "    if sort_by and sort_by in df.columns:\n",
    "        df = df.sort_values(by=sort_by, ascending=False)\n",
    "\n",
    "    # Limit rows\n",
    "    df = df.head(top_n)\n",
    "\n",
    "    try:\n",
    "        # Jupyter pretty table with gradient\n",
    "        return df.style.background_gradient(cmap=\"Blues\")\n",
    "    except Exception:\n",
    "        # Fallback for console\n",
    "        pd.set_option(\"display.max_columns\", None)\n",
    "        pd.set_option(\"display.width\", 150)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6390d1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_298d1 th {\n",
       "  font-size: 15pt;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_298d1 td {\n",
       "  font-size: 18pt;\n",
       "  text-align: center;\n",
       "  width: 150px;\n",
       "}\n",
       "#T_298d1 tr {\n",
       "  height: 50px;\n",
       "}\n",
       "#T_298d1_row0_col1, #T_298d1_row0_col3, #T_298d1_row0_col4, #T_298d1_row0_col5, #T_298d1_row0_col6, #T_298d1_row3_col2, #T_298d1_row3_col4, #T_298d1_row3_col6, #T_298d1_row4_col2, #T_298d1_row4_col4, #T_298d1_row4_col6, #T_298d1_row5_col1, #T_298d1_row5_col3, #T_298d1_row5_col4, #T_298d1_row5_col5, #T_298d1_row5_col6 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_298d1_row0_col2, #T_298d1_row5_col2 {\n",
       "  background-color: #5ba3d0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_298d1_row1_col1, #T_298d1_row1_col2, #T_298d1_row2_col1, #T_298d1_row2_col2 {\n",
       "  background-color: #1865ac;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_298d1_row1_col3, #T_298d1_row1_col4, #T_298d1_row2_col3, #T_298d1_row2_col4 {\n",
       "  background-color: #1d6cb1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_298d1_row1_col5, #T_298d1_row2_col5 {\n",
       "  background-color: #2676b8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_298d1_row1_col6, #T_298d1_row2_col6 {\n",
       "  background-color: #2777b8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_298d1_row3_col1, #T_298d1_row3_col3, #T_298d1_row4_col1, #T_298d1_row4_col3 {\n",
       "  background-color: #c7dcef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_298d1_row3_col5, #T_298d1_row4_col5 {\n",
       "  background-color: #f6faff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_298d1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_298d1_level0_col0\" class=\"col_heading level0 col0\" >utterance</th>\n",
       "      <th id=\"T_298d1_level0_col1\" class=\"col_heading level0 col1\" >1 - entropy</th>\n",
       "      <th id=\"T_298d1_level0_col2\" class=\"col_heading level0 col2\" >1 - probability</th>\n",
       "      <th id=\"T_298d1_level0_col3\" class=\"col_heading level0 col3\" >2 - entropy</th>\n",
       "      <th id=\"T_298d1_level0_col4\" class=\"col_heading level0 col4\" >2 - probability</th>\n",
       "      <th id=\"T_298d1_level0_col5\" class=\"col_heading level0 col5\" >3 - entropy</th>\n",
       "      <th id=\"T_298d1_level0_col6\" class=\"col_heading level0 col6\" >3 - probability</th>\n",
       "      <th id=\"T_298d1_level0_col7\" class=\"col_heading level0 col7\" >Last Method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_298d1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_298d1_row0_col0\" class=\"data row0 col0\" >(0, 0)</td>\n",
       "      <td id=\"T_298d1_row0_col1\" class=\"data row0 col1\" >0.000</td>\n",
       "      <td id=\"T_298d1_row0_col2\" class=\"data row0 col2\" >0.550</td>\n",
       "      <td id=\"T_298d1_row0_col3\" class=\"data row0 col3\" >0.000</td>\n",
       "      <td id=\"T_298d1_row0_col4\" class=\"data row0 col4\" >0.000</td>\n",
       "      <td id=\"T_298d1_row0_col5\" class=\"data row0 col5\" >0.000</td>\n",
       "      <td id=\"T_298d1_row0_col6\" class=\"data row0 col6\" >0.000</td>\n",
       "      <td id=\"T_298d1_row0_col7\" class=\"data row0 col7\" >(np.float64(0.0), {'inf': np.float64(1.0), 'high': np.float64(0.0), 'low': np.float64(0.0)})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_298d1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_298d1_row1_col0\" class=\"data row1 col0\" >(1, 7)</td>\n",
       "      <td id=\"T_298d1_row1_col1\" class=\"data row1 col1\" >0.795</td>\n",
       "      <td id=\"T_298d1_row1_col2\" class=\"data row1 col2\" >0.795</td>\n",
       "      <td id=\"T_298d1_row1_col3\" class=\"data row1 col3\" >0.767</td>\n",
       "      <td id=\"T_298d1_row1_col4\" class=\"data row1 col4\" >0.767</td>\n",
       "      <td id=\"T_298d1_row1_col5\" class=\"data row1 col5\" >0.729</td>\n",
       "      <td id=\"T_298d1_row1_col6\" class=\"data row1 col6\" >0.726</td>\n",
       "      <td id=\"T_298d1_row1_col7\" class=\"data row1 col7\" >(np.float64(0.7666520527934004), {'inf': np.float64(-2.5777607614938964), 'high': np.float64(2.9535569398378456), 'low': np.float64(0.624203821656051)})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_298d1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_298d1_row2_col0\" class=\"data row2 col0\" >(0, 6)</td>\n",
       "      <td id=\"T_298d1_row2_col1\" class=\"data row2 col1\" >0.795</td>\n",
       "      <td id=\"T_298d1_row2_col2\" class=\"data row2 col2\" >0.795</td>\n",
       "      <td id=\"T_298d1_row2_col3\" class=\"data row2 col3\" >0.767</td>\n",
       "      <td id=\"T_298d1_row2_col4\" class=\"data row2 col4\" >0.767</td>\n",
       "      <td id=\"T_298d1_row2_col5\" class=\"data row2 col5\" >0.729</td>\n",
       "      <td id=\"T_298d1_row2_col6\" class=\"data row2 col6\" >0.726</td>\n",
       "      <td id=\"T_298d1_row2_col7\" class=\"data row2 col7\" >(np.float64(0.7666520527934004), {'inf': np.float64(-4.622063872026909), 'high': np.float64(4.287810405932377), 'low': np.float64(1.3342534660945318)})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_298d1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_298d1_row3_col0\" class=\"data row3 col0\" >(4, 7)</td>\n",
       "      <td id=\"T_298d1_row3_col1\" class=\"data row3 col1\" >0.245</td>\n",
       "      <td id=\"T_298d1_row3_col2\" class=\"data row3 col2\" >0.000</td>\n",
       "      <td id=\"T_298d1_row3_col3\" class=\"data row3 col3\" >0.245</td>\n",
       "      <td id=\"T_298d1_row3_col4\" class=\"data row3 col4\" >0.000</td>\n",
       "      <td id=\"T_298d1_row3_col5\" class=\"data row3 col5\" >0.007</td>\n",
       "      <td id=\"T_298d1_row3_col6\" class=\"data row3 col6\" >0.000</td>\n",
       "      <td id=\"T_298d1_row3_col7\" class=\"data row3 col7\" >(np.float64(0.2454492598058947), {'inf': np.float64(0.7545507401941053), 'high': np.float64(0.2454492598058947), 'low': np.float64(0.0)})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_298d1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_298d1_row4_col0\" class=\"data row4 col0\" >(0, 3)</td>\n",
       "      <td id=\"T_298d1_row4_col1\" class=\"data row4 col1\" >0.245</td>\n",
       "      <td id=\"T_298d1_row4_col2\" class=\"data row4 col2\" >0.000</td>\n",
       "      <td id=\"T_298d1_row4_col3\" class=\"data row4 col3\" >0.245</td>\n",
       "      <td id=\"T_298d1_row4_col4\" class=\"data row4 col4\" >0.000</td>\n",
       "      <td id=\"T_298d1_row4_col5\" class=\"data row4 col5\" >0.007</td>\n",
       "      <td id=\"T_298d1_row4_col6\" class=\"data row4 col6\" >0.000</td>\n",
       "      <td id=\"T_298d1_row4_col7\" class=\"data row4 col7\" >(np.float64(0.2454492598058947), {'inf': np.float64(-2.190840377476631), 'high': np.float64(2.209043338253052), 'low': np.float64(0.9817970392235787)})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_298d1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_298d1_row5_col0\" class=\"data row5 col0\" >(7, 7)</td>\n",
       "      <td id=\"T_298d1_row5_col1\" class=\"data row5 col1\" >0.000</td>\n",
       "      <td id=\"T_298d1_row5_col2\" class=\"data row5 col2\" >0.550</td>\n",
       "      <td id=\"T_298d1_row5_col3\" class=\"data row5 col3\" >0.000</td>\n",
       "      <td id=\"T_298d1_row5_col4\" class=\"data row5 col4\" >0.000</td>\n",
       "      <td id=\"T_298d1_row5_col5\" class=\"data row5 col5\" >0.000</td>\n",
       "      <td id=\"T_298d1_row5_col6\" class=\"data row5 col6\" >0.000</td>\n",
       "      <td id=\"T_298d1_row5_col7\" class=\"data row5 col7\" >(np.float64(0.0), {'inf': np.float64(1.0), 'high': np.float64(0.0), 'low': np.float64(0.0)})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x224cd532ad0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "UTT_PROB_METHODS = {\n",
    "    # \"p(u' | u*)_0\": lambda utt, utterances, domain, psi_prior, alpha:\n",
    "    #     get_utterance_prob_0(utt, utterances, domain),\n",
    "    \"1\": lambda utt, utterances, domain, psi_prior, alpha:\n",
    "        get_utterance_prob_1(utt, utterances, domain, alpha),\n",
    "    \"2\": lambda utt, utterances, domain, psi_prior, alpha:\n",
    "        get_utterance_prob_2(utt, utterances, domain, alpha),\n",
    "    \"3\": lambda utt, utterances, domain, psi_prior, alpha:\n",
    "        get_utterance_prob_3(utt, utterances, domain, psi_prior, alpha),\n",
    "}\n",
    "\n",
    "SUSPICION_METHODS = {\n",
    "    \"entropy\": lambda utt, domain, utterance_prob:\n",
    "        sus_entropy_l(utt, domain, get_entropy_dist(domain, utterance_prob)),\n",
    "    \"probability\": lambda utt, domain, utterance_prob:\n",
    "        sus_probability(utt, utterance_prob),\n",
    "}\n",
    "\n",
    "def compute_all_suspicions(utterances, domain, psi_prior, alpha=5.0):\n",
    "    results = []\n",
    "    for utt in utterances:\n",
    "        row = {\"utterance\": utt}\n",
    "        for prob_name, prob_func in UTT_PROB_METHODS.items():\n",
    "            utterance_prob = prob_func(utt, utterances, domain, psi_prior, alpha)\n",
    "            for sus_name, sus_func in SUSPICION_METHODS.items():\n",
    "                key = f\"{prob_name} - {sus_name}\"\n",
    "                row[key] = sus_func(utt, domain, utterance_prob)\n",
    "        results.append(row)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "min_interval = 3\n",
    "max_interval = 5\n",
    "domain = (0, 19)\n",
    "domain = (0, 7)\n",
    "alpha = 3.0\n",
    "utterances = create_all_utterances(min_interval, max_interval, domain)\n",
    "#utterances = [(0, 0), (1, 19), (0, 18), (10, 19), (0, 9), (19, 19)]\n",
    "utterances = [(0, 0), (1, 7), (0, 6), (4, 7), (0, 3), (7, 7)]\n",
    "# utterances = [(0, 0), (1, 1), (2, 2), (0, 2)]\n",
    "\n",
    "# for i in range(3, 12):\n",
    "#     utterances.append((i, i + 9))\n",
    "psi_prior = {\"inf\": 1.0, \"high\": 0.0, \"low\": 0.0}\n",
    "\n",
    "proper_result = []\n",
    "for utt in utterances:\n",
    "    proper_result.append(sus_proper(utt, utterances, domain, alpha=alpha))\n",
    "    #print(f\"Utterance: {utt}, Suspicion: {sus_proper(utt, utterances, domain, alpha=alpha)}\")\n",
    "\n",
    "df = compute_all_suspicions(utterances, domain, psi_prior, alpha=alpha).head(100)\n",
    "df[\"Last Method\"] = proper_result\n",
    "\n",
    "df.style.background_gradient(cmap=\"Blues\", vmin=0, vmax=1).format(precision=3).set_table_styles([\n",
    "       {\"selector\": \"th\", \"props\": [(\"font-size\", \"15pt\"), (\"text-align\", \"center\")]},  \n",
    "       {\"selector\": \"td\", \"props\": [(\"font-size\", \"18pt\"), (\"text-align\", \"center\"), (\"width\", \"150px\")]},    \n",
    "        {\"selector\": \"tr\", \"props\": [(\"height\", \"50px\")]}   \n",
    "   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00cfffff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inf': np.float64(-2.5777607614938964), 'high': np.float64(2.9535569398378456), 'low': np.float64(0.624203821656051)}\n",
      "Suspicion proper: 0.7666520527934004\n",
      "State: 0, Inf: 0.0, Sus: 0.0\n",
      "State: 1, Inf: 0.16608356545961003, Sus: 0.22256250291403168\n",
      "State: 2, Inf: 0.16608356545961003, Sus: 0.22256250291403168\n",
      "State: 3, Inf: 0.16608356545961003, Sus: 0.22256250291403168\n",
      "State: 4, Inf: 0.16608356545961003, Sus: 0.07289696781089398\n",
      "State: 5, Inf: 0.16608356545961003, Sus: 0.07289696781089398\n",
      "State: 6, Inf: 0.16608356545961003, Sus: 0.07289696781089398\n",
      "State: 7, Inf: 0.0034986072423398326, Sus: 0.11362158782522304\n"
     ]
    }
   ],
   "source": [
    "utt = (1, 7)\n",
    "\n",
    "x_1, pmf_1 = pragmatic_listener_inf(utt, utterances, domain, alpha=alpha)\n",
    "susa, sus_psi_prior = sus_proper(utt, utterances, domain, alpha=alpha)\n",
    "psi_prior = sus_psi_prior\n",
    "print(psi_prior)\n",
    "\n",
    "x, pmf = pragmatic_listener(utt, utterances, domain, psi_prior, alpha=alpha)\n",
    "print(f\"Suspicion proper: {susa}\")\n",
    "\n",
    "for state in x_1:\n",
    "    print(f\"State: {state}, Inf: {pmf_1[x_1.index(state)]}, Sus: {pmf[x.index(state)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f44f7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X axis values (states)\n",
    "x = np.array([0, 1, 2, 3])\n",
    "\n",
    "# Probability distributions\n",
    "L_u0 = [0.5, 0.0, 0.25, 0.25]\n",
    "L_u1 = [0.5, 0.5, 0.0, 0.0]\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "\n",
    "# First distribution\n",
    "axes[0].bar(x, L_u0, color=\"skyblue\", edgecolor=\"black\")\n",
    "axes[0].set_title(r\"$L_0(s \\mid u_0)$\")\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_ylim(0, 0.6)\n",
    "axes[0].set_ylabel(\"Probability\")\n",
    "\n",
    "axes[1].bar(x, L_u1, color=\"salmon\", edgecolor=\"black\")\n",
    "axes[1].set_title(r\"$L_0(s \\mid u_1)$\")\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_ylim(0, 1)\n",
    "plt.yticks([0.25, 0.50, 0.75, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fa72fc",
   "metadata": {},
   "source": [
    "# How to \n",
    "\\begin{equation}\n",
    "S^* = \\arg\\min_{S} \\Big[ D_{\\mathrm{KL}}(S \\,\\|\\, S_1) - D_{\\mathrm{KL}}(S \\,\\|\\, S_2) \\Big]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7406ab55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utt_idx = 40# e.g. first utterance\n",
    "row = df.iloc[utt_idx].drop(\"utterance\")\n",
    "\n",
    "row.plot(kind=\"bar\", figsize=(8,4))\n",
    "plt.title(f\"Suspicion values for utterance {df.iloc[utt_idx]['utterance']}\")\n",
    "plt.ylabel(\"Suspicion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ddf20a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d664a_row0_col1, #T_d664a_row0_col3, #T_d664a_row0_col4, #T_d664a_row0_col5, #T_d664a_row0_col6, #T_d664a_row3_col2, #T_d664a_row3_col4, #T_d664a_row3_col5, #T_d664a_row3_col6, #T_d664a_row4_col4, #T_d664a_row4_col5, #T_d664a_row4_col6, #T_d664a_row5_col1, #T_d664a_row5_col3, #T_d664a_row5_col4, #T_d664a_row5_col5, #T_d664a_row5_col6 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d664a_row0_col2, #T_d664a_row1_col1, #T_d664a_row1_col3, #T_d664a_row1_col4, #T_d664a_row1_col5, #T_d664a_row1_col6, #T_d664a_row2_col1, #T_d664a_row2_col3, #T_d664a_row2_col4, #T_d664a_row2_col5, #T_d664a_row2_col6, #T_d664a_row5_col2 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d664a_row1_col2, #T_d664a_row2_col2 {\n",
       "  background-color: #084d96;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d664a_row3_col1, #T_d664a_row4_col1 {\n",
       "  background-color: #e2edf8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d664a_row3_col3, #T_d664a_row4_col3 {\n",
       "  background-color: #e1edf8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d664a_row4_col2 {\n",
       "  background-color: #82bbdb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d664a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d664a_level0_col0\" class=\"col_heading level0 col0\" >utterance</th>\n",
       "      <th id=\"T_d664a_level0_col1\" class=\"col_heading level0 col1\" >sus_entropy_prob1</th>\n",
       "      <th id=\"T_d664a_level0_col2\" class=\"col_heading level0 col2\" >sus_probability_prob1</th>\n",
       "      <th id=\"T_d664a_level0_col3\" class=\"col_heading level0 col3\" >sus_entropy_prob2</th>\n",
       "      <th id=\"T_d664a_level0_col4\" class=\"col_heading level0 col4\" >sus_probability_prob2</th>\n",
       "      <th id=\"T_d664a_level0_col5\" class=\"col_heading level0 col5\" >sus_entropy_prob3</th>\n",
       "      <th id=\"T_d664a_level0_col6\" class=\"col_heading level0 col6\" >sus_probability_prob3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d664a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d664a_row0_col0\" class=\"data row0 col0\" >(0, 0)</td>\n",
       "      <td id=\"T_d664a_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_d664a_row0_col2\" class=\"data row0 col2\" >0.904763</td>\n",
       "      <td id=\"T_d664a_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "      <td id=\"T_d664a_row0_col4\" class=\"data row0 col4\" >0.000000</td>\n",
       "      <td id=\"T_d664a_row0_col5\" class=\"data row0 col5\" >0.000000</td>\n",
       "      <td id=\"T_d664a_row0_col6\" class=\"data row0 col6\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d664a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d664a_row1_col0\" class=\"data row1 col0\" >(1, 20)</td>\n",
       "      <td id=\"T_d664a_row1_col1\" class=\"data row1 col1\" >0.897813</td>\n",
       "      <td id=\"T_d664a_row1_col2\" class=\"data row1 col2\" >0.802576</td>\n",
       "      <td id=\"T_d664a_row1_col3\" class=\"data row1 col3\" >0.892703</td>\n",
       "      <td id=\"T_d664a_row1_col4\" class=\"data row1 col4\" >0.842704</td>\n",
       "      <td id=\"T_d664a_row1_col5\" class=\"data row1 col5\" >0.500007</td>\n",
       "      <td id=\"T_d664a_row1_col6\" class=\"data row1 col6\" >0.500006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d664a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d664a_row2_col0\" class=\"data row2 col0\" >(0, 19)</td>\n",
       "      <td id=\"T_d664a_row2_col1\" class=\"data row2 col1\" >0.897813</td>\n",
       "      <td id=\"T_d664a_row2_col2\" class=\"data row2 col2\" >0.802576</td>\n",
       "      <td id=\"T_d664a_row2_col3\" class=\"data row2 col3\" >0.892703</td>\n",
       "      <td id=\"T_d664a_row2_col4\" class=\"data row2 col4\" >0.842704</td>\n",
       "      <td id=\"T_d664a_row2_col5\" class=\"data row2 col5\" >0.500007</td>\n",
       "      <td id=\"T_d664a_row2_col6\" class=\"data row2 col6\" >0.500006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d664a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d664a_row3_col0\" class=\"data row3 col0\" >(11, 20)</td>\n",
       "      <td id=\"T_d664a_row3_col1\" class=\"data row3 col1\" >0.095237</td>\n",
       "      <td id=\"T_d664a_row3_col2\" class=\"data row3 col2\" >0.000000</td>\n",
       "      <td id=\"T_d664a_row3_col3\" class=\"data row3 col3\" >0.099999</td>\n",
       "      <td id=\"T_d664a_row3_col4\" class=\"data row3 col4\" >0.000000</td>\n",
       "      <td id=\"T_d664a_row3_col5\" class=\"data row3 col5\" >0.000002</td>\n",
       "      <td id=\"T_d664a_row3_col6\" class=\"data row3 col6\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d664a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d664a_row4_col0\" class=\"data row4 col0\" >(0, 9)</td>\n",
       "      <td id=\"T_d664a_row4_col1\" class=\"data row4 col1\" >0.095237</td>\n",
       "      <td id=\"T_d664a_row4_col2\" class=\"data row4 col2\" >0.401288</td>\n",
       "      <td id=\"T_d664a_row4_col3\" class=\"data row4 col3\" >0.099999</td>\n",
       "      <td id=\"T_d664a_row4_col4\" class=\"data row4 col4\" >0.000000</td>\n",
       "      <td id=\"T_d664a_row4_col5\" class=\"data row4 col5\" >0.000002</td>\n",
       "      <td id=\"T_d664a_row4_col6\" class=\"data row4 col6\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d664a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d664a_row5_col0\" class=\"data row5 col0\" >(20, 20)</td>\n",
       "      <td id=\"T_d664a_row5_col1\" class=\"data row5 col1\" >0.000000</td>\n",
       "      <td id=\"T_d664a_row5_col2\" class=\"data row5 col2\" >0.904763</td>\n",
       "      <td id=\"T_d664a_row5_col3\" class=\"data row5 col3\" >0.000000</td>\n",
       "      <td id=\"T_d664a_row5_col4\" class=\"data row5 col4\" >0.000000</td>\n",
       "      <td id=\"T_d664a_row5_col5\" class=\"data row5 col5\" >0.000000</td>\n",
       "      <td id=\"T_d664a_row5_col6\" class=\"data row5 col6\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ba1b493ed0>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pretty_table(df, sort_by=None, top_n=10, decimals=3):\n",
    "    \"\"\"\n",
    "    Display a nice-looking table of suspicion results.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Results DataFrame\n",
    "        sort_by (str, optional): Column to sort by\n",
    "        top_n (int): Number of rows to show\n",
    "        decimals (int): Rounding of floats\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame (console) or pd.Styler (Jupyter)\n",
    "    \"\"\"\n",
    "    # Round floats\n",
    "    #df = df.round(decimals)\n",
    "\n",
    "    # Optional sort\n",
    "    if sort_by and sort_by in df.columns:\n",
    "        df = df.sort_values(by=sort_by, ascending=False)\n",
    "\n",
    "    # Limit rows\n",
    "    df = df.head(top_n)\n",
    "\n",
    "    try:\n",
    "        # Jupyter pretty table with gradient\n",
    "        return df.style.background_gradient(cmap=\"Blues\")\n",
    "    except Exception:\n",
    "        # Fallback for console\n",
    "        pd.set_option(\"display.max_columns\", None)\n",
    "        pd.set_option(\"display.width\", 150)\n",
    "        return df\n",
    "pretty_table(df, top_n=54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad0061af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy(utt, domain):\n",
    "    x, pmf = literal_listener(utt, domain)\n",
    "    pmf = pmf[pmf > 0]  # Filter out zero probabilities\n",
    "    entropy = -np.sum(pmf * np.log2(pmf))\n",
    "    return entropy\n",
    "\n",
    "def posterior_utterance_distribution(utt, utterances, domain, alpha=3.0):\n",
    "    utterance_probs = {u: 0.0 for u in utterances}\n",
    "    all_states = np.arange(domain[0], domain[1] + 1)\n",
    "    for state in all_states:\n",
    "        x_state, pmf_state = pragmatic_listener_inf(utt, utterances, domain, alpha=alpha)\n",
    "        speaker_utt_probs = pragmatic_speaker(state, \"inf\", utterances, domain, alpha=alpha)\n",
    "        for u in utterances:\n",
    "            utterance_probs[u] += pmf_state[x_state.index(state)] * speaker_utt_probs[u]\n",
    "            \n",
    "    return utterance_probs\n",
    "\n",
    "def entropy_distribution(utt, utterances, domain, alpha=3.0):\n",
    "    utterance_probs = posterior_utterance_distribution(utt, utterances, domain, alpha=alpha)\n",
    "    entropies = {}\n",
    "    for u, prob in utterance_probs.items():\n",
    "        entropy = get_entropy(u, domain)\n",
    "        entropies[entropy] = entropies.get(entropy, 0) + prob\n",
    "    x, pmf = zip(*sorted(entropies.items()))\n",
    "    return x, pmf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d92c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suspicion_pvalue(utt, utterances, domain, belief, alpha=3.0):\n",
    "    x_ent, pmf_ent = entropy_distribution(utt, utterances, domain, alpha=alpha)\n",
    "    utt_ent = get_entropy(utt, domain)\n",
    "    suspicion = 0\n",
    "    for i in range(len(x_ent)):\n",
    "        if x_ent[i] < utt_ent:\n",
    "            suspicion += pmf_ent[i]\n",
    "    return suspicion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
